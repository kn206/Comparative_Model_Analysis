{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1-Bw-rbIOHA9DFAkf0V1wqJUXEomfbCzC",
      "authorship_tag": "ABX9TyP2L8K24M2rCHPY5Qfeu5QK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kn206/Comparative_Model_Analysis/blob/main/pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import random_split"
      ],
      "metadata": {
        "id": "Lso-EYQdXSjZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the Data**"
      ],
      "metadata": {
        "id": "xlrAdHR3dWgt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TVbx4iXHOo45",
        "outputId": "f1d4c11e-c749-4952-c3c5-a3cbe1859a60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   -0.0002947738  -0.0002931319  -0.0002915017  -0.0002898787  -0.0002882734  \\\n",
            "0      -0.000442      -0.000440      -0.000437      -0.000435      -0.000432   \n",
            "1      -0.000590      -0.000586      -0.000583      -0.000580      -0.000577   \n",
            "2      -0.000737      -0.000733      -0.000729      -0.000725      -0.000721   \n",
            "3      -0.000884      -0.000879      -0.000875      -0.000870      -0.000865   \n",
            "4      -0.001032      -0.001026      -0.001020      -0.001015      -0.001009   \n",
            "\n",
            "   -0.0002867076  -0.0002852272  -0.0002839193  -0.00028291  -0.0002823782  \\\n",
            "0      -0.000430      -0.000428      -0.000426    -0.000424      -0.000424   \n",
            "1      -0.000573      -0.000570      -0.000568    -0.000566      -0.000565   \n",
            "2      -0.000717      -0.000713      -0.000710    -0.000707      -0.000706   \n",
            "3      -0.000860      -0.000856      -0.000852    -0.000849      -0.000847   \n",
            "4      -0.001003      -0.000998      -0.000994    -0.000990      -0.000988   \n",
            "\n",
            "   ...  0.5990  0.5991  0.5992  0.5993  0.5994  0.5995  0.5996  0.5997  \\\n",
            "0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "1  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "2  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "3  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "4  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "\n",
            "   0.5998  0.0230432  \n",
            "0     0.0   0.034319  \n",
            "1     0.0   0.045593  \n",
            "2     0.0   0.056914  \n",
            "3     0.0   0.066750  \n",
            "4     0.0   0.074425  \n",
            "\n",
            "[5 rows x 10000 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load data from an Excel file\n",
        "df = pd.read_excel('/content/sample_data/data.xlsx')\n",
        "\n",
        "# View the first few rows of the data\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and validation sets in a 80/20 ratio\n",
        "train_set, val_set = random_split(df, [0.8, 0.2])\n"
      ],
      "metadata": {
        "id": "eWu_wC_MVgHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a DataLoader object for the training set\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "\n",
        "# Creating a DataLoader object for the validation set\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "3gsniro5VtuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a loss function\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "# Define an optimizer\n",
        "optimizer = torch.optim.Adam(net.parameters())"
      ],
      "metadata": {
        "id": "K1E11MQSXxmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install pandas\n",
        "#pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sKPoOnm4-jD3",
        "outputId": "91ba59fe-4de8-40ad-e048-ca3381be32c4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K-means and PCA**"
      ],
      "metadata": {
        "id": "utmCHbpRcdRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#K-Means Clustering\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Assuming you want to use all columns as features (adjust as needed)\n",
        "data_tensor = torch.tensor(df.values, dtype=torch.float32)\n",
        "\n",
        "# Specify the number of clusters (you can adjust this)\n",
        "num_clusters = 3\n",
        "\n",
        "# Create a K-Means model and fit it to your data\n",
        "kmeans = KMeans(n_clusters=num_clusters)\n",
        "cluster_labels = kmeans.fit_predict(data_tensor)\n",
        "\n",
        "# The cluster labels can provide information about the grouping of data points\n",
        "print(\"Cluster Labels:\")\n",
        "print(cluster_labels)\n",
        "\n",
        "#Principal Component Analysis (PCA)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Load data from an Excel file\n",
        "\n",
        "# Assuming you want to use all columns as features (adjust as needed)\n",
        "data_tensor = torch.tensor(df.values, dtype=torch.float32)\n",
        "\n",
        "# Specify the number of components (dimensions) you want to reduce to\n",
        "num_components = 2\n",
        "\n",
        "# Create a PCA model and fit it to your data\n",
        "pca = PCA(n_components=num_components)\n",
        "reduced_data = pca.fit_transform(data_tensor)\n",
        "\n",
        "# The reduced_data now contains your data in lower dimensions\n",
        "print(\"Reduced Data:\")\n",
        "print(reduced_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8C_KbO_v9XjN",
        "outputId": "287f1015-3a8c-46de-e661-1075a05b3b7d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Labels:\n",
            "[2 2 2 ... 2 2 2]\n",
            "Reduced Data:\n",
            "[[-0.21091516 -0.10214426]\n",
            " [-0.21352296 -0.09781782]\n",
            " [-0.21612183 -0.09348952]\n",
            " ...\n",
            " [-0.13757056 -0.15893268]\n",
            " [-0.12515218 -0.17071379]\n",
            " [-0.11416509 -0.18279433]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Calculate the Silhouette Score\n",
        "silhouette_avg = silhouette_score(data_tensor, cluster_labels)\n",
        "print(f\"Silhouette Score: {silhouette_avg:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "M8hGUF-MADG-",
        "outputId": "6de38793-943b-4440-f6b1-321a57496abd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette Score: 0.48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the inertia (within-cluster sum of squares)\n",
        "inertia = kmeans.inertia_\n",
        "print(f\"Inertia: {inertia:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wSWZoNEJAGio",
        "outputId": "278c66ec-6514-4581-9bdb-41ba919eb027"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inertia: 310780.70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load your data from the DataFrame\n",
        "# Replace 'df' with your DataFrame\n",
        "X = df.iloc[:, :-1]  # Features (all columns except the last one)\n",
        "y = df.iloc[:, -1]   # Target variable (the last column)\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X = torch.tensor(X.values, dtype=torch.float32)\n",
        "y = torch.tensor(y.values, dtype=torch.long)  # Assuming integer class labels\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a simple classification model using PyTorch\n",
        "class ClassificationModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ClassificationModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(X_train.shape[1], 64)\n",
        "        self.fc2 = nn.Linear(64, 2)  # Output layer for binary classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "LKcphf-tCyH9",
        "outputId": "bcfe83aa-7745-47d7-f79c-73478e209d82"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RegressionModel(\n",
              "  (fc1): Linear(in_features=9999, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Regression**"
      ],
      "metadata": {
        "id": "CtpuwHkScG2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "# Load your data from the DataFrame\n",
        "# Replace 'df' with your DataFrame\n",
        "X = df.iloc[:, :-1]  # Features (all columns except the last one)\n",
        "y = df.iloc[:, -1]   # Target variable (the last column)\n",
        "\n",
        "# Normalize the input features\n",
        "X = (X - X.mean()) / X.std()\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X = torch.tensor(X.values, dtype=torch.float32)\n",
        "y = torch.tensor(y.values, dtype=torch.float32)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a more complex regression model using PyTorch\n",
        "class RegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RegressionModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(X_train.shape[1], 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = RegressionModel()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adjust learning rate\n",
        "\n",
        "# Train the model with more epochs\n",
        "num_epochs = 500\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train.view(-1, 1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model(X_test).detach().numpy()\n",
        "\n",
        "# Calculate R^2 and MSE\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(f'Regression R^2 Score: {r2:.2f}')\n",
        "print(f'Regression Mean Squared Error: {mse:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eIF8stoeF4b2",
        "outputId": "41ee5368-f9e1-4ae0-e680-7631062ffd19"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression R^2 Score: 0.81\n",
            "Regression Mean Squared Error: 0.29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "# Load your data from the DataFrame\n",
        "# Replace 'df' with your DataFrame\n",
        "X = df.iloc[:, :-1]  # Features (all columns except the last one)\n",
        "y = df.iloc[:, -1]   # Target variable (the last column)\n",
        "\n",
        "# Normalize the input features\n",
        "X = (X - X.mean()) / X.std()\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X = torch.tensor(X.values, dtype=torch.float32)\n",
        "y = torch.tensor(y.values, dtype=torch.float32)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a more complex regression model using PyTorch\n",
        "class RegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RegressionModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(X_train.shape[1], 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = RegressionModel()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adjust learning rate\n",
        "\n",
        "# Train the model with more epochs\n",
        "num_epochs = 500\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train.view(-1, 1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model(X_test).detach().numpy()\n",
        "\n",
        "# Calculate R^2 and MSE\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(f'Regression R^2 Score: {r2:.2f}')\n",
        "print(f'Regression Mean Squared Error: {mse:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6BW3pNHDGoTN",
        "outputId": "9e5e6269-a60d-4d56-aad7-b2b09950ca2b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression R^2 Score: 0.85\n",
            "Regression Mean Squared Error: 0.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gaussian Process regression**"
      ],
      "metadata": {
        "id": "FNkJv-avbGUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gpytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8KwwXBVxNCvl",
        "outputId": "89015d3a-f1dd-43b2-b9ea-b18423f0bd14"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gpytorch\n",
            "  Downloading gpytorch-1.11-py3-none-any.whl (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.1/266.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from gpytorch) (1.2.2)\n",
            "Collecting linear-operator>=0.5.0 (from gpytorch)\n",
            "  Downloading linear_operator-0.5.2-py3-none-any.whl (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.6/175.6 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.11 in /usr/local/lib/python3.10/dist-packages (from linear-operator>=0.5.0->gpytorch) (2.0.1+cu118)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from linear-operator>=0.5.0->gpytorch) (1.11.2)\n",
            "Collecting jaxtyping>=0.2.9 (from linear-operator>=0.5.0->gpytorch)\n",
            "  Downloading jaxtyping-0.2.22-py3-none-any.whl (25 kB)\n",
            "Collecting typeguard~=2.13.3 (from linear-operator>=0.5.0->gpytorch)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch) (1.23.5)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.10/dist-packages (from jaxtyping>=0.2.9->linear-operator>=0.5.0->gpytorch) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11->linear-operator>=0.5.0->gpytorch) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11->linear-operator>=0.5.0->gpytorch) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11->linear-operator>=0.5.0->gpytorch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11->linear-operator>=0.5.0->gpytorch) (1.3.0)\n",
            "Installing collected packages: typeguard, jaxtyping, linear-operator, gpytorch\n",
            "Successfully installed gpytorch-1.11 jaxtyping-0.2.22 linear-operator-0.5.2 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import gpytorch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "# Load your data from the DataFrame\n",
        "# Replace 'df' with your DataFrame\n",
        "X = df.iloc[:, :-1]  # Features (all columns except the last one)\n",
        "y = df.iloc[:, -1]   # Target variable (the last column)\n",
        "\n",
        "# Normalize the input features if needed\n",
        "# X = (X - X.mean()) / X.std()\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "#X = torch.tensor(X.values, dtype=torch.float32)\n",
        "#y = torch.tensor(y.values, dtype=torch.float32)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a Gaussian Process regression model using GPyTorch\n",
        "#class GPRegressionModel(gpytorch.models.ExactGP):\n",
        "    #def __init__(self, train_x, train_y, likelihood):\n",
        "        #super(GPRegressionModel, self).__init__(train_x, train_y, likelihood)\n",
        "        #self.mean_module = gpytorch.means.ConstantMean()\n",
        "        #self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
        "\n",
        "    #def forward(self, x):\n",
        "        #mean_x = self.mean_module(x)\n",
        "        #covar_x = self.covar_module(x)\n",
        "        #return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
        "\n",
        "# Initialize likelihood and model\n",
        "#likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
        "#model = GPRegressionModel(X_train, y_train, likelihood)\n",
        "\n",
        "# Training the model\n",
        "#model.train()\n",
        "#likelihood.train()\n",
        "\n",
        "# Use the Adam optimizer for model parameters only\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
        "\n",
        "# Define a training loop\n",
        "#n_epochs = 1000  # Increase the number of epochs\n",
        "#for epoch in range(n_epochs):\n",
        "    #optimizer.zero_grad()\n",
        "    #output = model(X_train)\n",
        "    #loss = -likelihood(output, y_train).log_prob(y_train).mean()  # Negative log-likelihood as loss\n",
        "    #loss.backward()\n",
        "    #optimizer.step()\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "#model.eval()\n",
        "#likelihood.eval()\n",
        "\n",
        "# Make predictions\n",
        "#with torch.no_grad():\n",
        "    #predicted_mean = model(X_test).mean\n",
        "\n",
        "# Calculate R^2 and MSE\n",
        "#r2 = r2_score(y_test.numpy(), predicted_mean.numpy())\n",
        "#mse = mean_squared_error(y_test.numpy(), predicted_mean.numpy())\n",
        "\n",
        "#print(f'GP Regression R^2 Score: {r2:.2f}')\n",
        "#print(f'GP Regression Mean Squared Error: {mse:.2f}')"
      ],
      "metadata": {
        "id": "81Y9_JGuM9ls"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Neural network**"
      ],
      "metadata": {
        "id": "Nw8zeftIbY8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import r2_score, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Loading the data from the DataFrame\n",
        "# Replace 'df' with your DataFrame\n",
        "X = df.iloc[:, :-1].values  # Features (all columns except the last one)\n",
        "y = df.iloc[:, -1].values   # Target variable (the last column)\n",
        "\n",
        "# Normalizing the input features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Converting data to PyTorch tensors\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Defining a customized neural network\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Initializing the model, loss function, and optimizer\n",
        "input_size = X_train.shape[1]\n",
        "model = Net(input_size)\n",
        "criterion = nn.MSELoss()  # For regression\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(2000):  # Increase the number of epochs\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_test)\n",
        "\n",
        "# Calculating R^2 and accuracy\n",
        "r2 = r2_score(y_test.numpy(), y_pred.numpy())\n",
        "\n",
        "#predicted_labels = (y_pred > 0.5).float()\n",
        "#accuracy = accuracy_score(y_test.numpy(), predicted_labels.numpy())\n",
        "\n",
        "print(f'R^2 Score: {r2:.2f}')\n",
        "#print(f'Accuracy: {accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "43R6mdWZT1Nw",
        "outputId": "fd9454cb-9e09-479d-fc48-9d2f36e60ea2"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R^2 Score: 0.82\n"
          ]
        }
      ]
    }
  ]
}